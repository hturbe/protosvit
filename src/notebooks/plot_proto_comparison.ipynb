{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of prototypes across images\n",
    "This notebook plots a random selection of images where a given prototypes is present. The aim is to show the consistency of the concepts used by the model to make a prediction across samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from os.path import join as pj\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyrootutils\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from matplotlib.patches import Rectangle\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "pyrootutils.setup_root(os.getcwd(), indicator=\".project-root\", pythonpath=True)\n",
    "from pathlib import Path\n",
    "\n",
    "from src.shared_utils.utils_visualisation import plot_prototypes, show_cam_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_sim =# add the path to the folder where the trained model is stored\n",
    "\n",
    "pkl_path = pj(path_sim, \"results_test.pkl\")\n",
    "with open(pkl_path, \"rb\") as f:\n",
    "    dict_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dict_results[\"labels\"]\n",
    "\n",
    "np_image = dict_results[\"sample\"]\n",
    "np_similarity = dict_results[\"similarity_prototype\"]\n",
    "pruned_importance = dict_results[\"importance\"].copy()\n",
    "pruned_importance[pruned_importance<0.1] = 0\n",
    "modified_preds = pruned_importance.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_normalize=torch.tensor([0.48145466, 0.4578275, 0.40821073]) # for medclip\n",
    "# std_normalize=torch.tensor([0.26862954, 0.26130258, 0.27577711]) # for medclip\n",
    "\n",
    "mean_normalize = torch.tensor([0.485, 0.456, 0.406])\n",
    "std_normalize = torch.tensor([0.229, 0.224, 0.225])\n",
    "unnormalize = transforms.Normalize(\n",
    "        (-mean_normalize / std_normalize), (1.0 / std_normalize),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_importance = pruned_importance[np.arange(pruned_importance.shape[0]), :, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_idx_used = np.argwhere((class_importance>0).sum(axis=0)>0).squeeze()\n",
    "print(list_idx_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorblind_palette = sns.color_palette(\"colorblind\", len(list_idx_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_per_figure = 16\n",
    "scale_factor =2\n",
    "nb_rows =4\n",
    "width = scale_factor*(proto_per_figure/nb_rows)\n",
    "height = scale_factor*nb_rows*1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_importance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_images = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if top_images:\n",
    "    path_save = Path(path_sim) / \"prototypes_organised_top\"\n",
    "else:\n",
    "    path_save = Path(path_sim) / \"prototypes_organised_random\"\n",
    "path_save.mkdir(exist_ok=True, parents=True)\n",
    "for idx_proto_analsyed in tqdm(list_idx_used):\n",
    "    if top_images:\n",
    "        list_images = class_importance[:, idx_proto_analsyed].argsort()[-proto_per_figure:][::-1]\n",
    "    else:\n",
    "        top_importance = np.argsort(class_importance, axis=1)[:, -6:]\n",
    "        list_images = np.argwhere((top_importance == idx_proto_analsyed).sum(axis=1)>0).squeeze()\n",
    "        np.random.shuffle(list_images)\n",
    "        list_images = list_images[:proto_per_figure]\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=int(proto_per_figure/nb_rows), nrows=nb_rows, figsize=(width, height))\n",
    "    for i,idx  in enumerate(list_images):\n",
    "        idx_figure = idx\n",
    "        image = np_image[idx_figure]\n",
    "        image = unnormalize(torch.tensor(image)).numpy()\n",
    "        label_tmp = labels[idx_figure]\n",
    "        pred_tmp = np.argmax(modified_preds[idx_figure])\n",
    "        importance_image = pruned_importance[idx_figure,:,label_tmp]\n",
    "        similarity = np_similarity[idx_figure]\n",
    "        img_size = image.shape[1:]\n",
    "        size_square_similarity = int(similarity.shape[1]**0.5)\n",
    "\n",
    "        similarity_proto = similarity[idx_proto_analsyed]\n",
    "        similiarity_tmp = similarity_proto.reshape(\n",
    "            size_square_similarity, size_square_similarity,\n",
    "        )\n",
    "        similarity_scaled = torch.nn.functional.interpolate(\n",
    "            torch.tensor(similiarity_tmp[None, None, :, :]),\n",
    "            size=img_size,\n",
    "            scale_factor=None,\n",
    "            mode=\"bilinear\",\n",
    "        )\n",
    "\n",
    "        similarity_plot = show_cam_on_image(\n",
    "            np.transpose(image,(1,2,0)),\n",
    "            similarity_scaled[0, 0].detach().cpu().numpy(),\n",
    "            alpha = 0.4,\n",
    "        )\n",
    "        #flatten axs and plot in the next available spot\n",
    "        axs.flatten()[i].imshow(similarity_plot,interpolation=\"nearest\")\n",
    "        axs.flatten()[i].axis(\"off\")\n",
    "        # axs.flatten()[i].title.set_text(f\"Pred: {df_disease.iloc[pred_tmp, 0]}, Label: {df_disease.iloc[label_tmp, 0]}\")\n",
    "        axs.flatten()[i].title.set_text(f\"Pred: {pred_tmp}, Label: {label_tmp}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path_save / f\"proto_{idx_proto_analsyed}.png\")\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

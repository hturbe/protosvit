{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot model's prediction across samples of the FunnyBirds dataset with interbention\n",
    "This notebook aims to show how the model's prediction changes as key parts of the images are supressed in the FunnyBird dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyrootutils\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from matplotlib.patches import Rectangle\n",
    "pyrootutils.setup_root(os.getcwd(), indicator=\".project-root\", pythonpath=True)\n",
    "import random\n",
    "from src.shared_utils.utils_visualisation import plot_prototypes\n",
    "from src.shared_utils.utils_experiments import  load_model_dataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from src.learning.data.FunnybirdsDataset import FunnyBirdsDataset\n",
    "from src.shared_utils.utils_visualisation import show_cam_on_image, return_colorblind_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path =\n",
    "path_sim =\n",
    "model, _ = load_model_dataset(path_sim=path_sim,set=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = FunnyBirdsDataset(\n",
    "        data_path,\n",
    "        \"test\",\n",
    "        get_part_map=True,\n",
    "        transform=transforms,\n",
    "        eval_funny_birds=True,\n",
    "    )\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_image = []\n",
    "output_all = []\n",
    "target_all = []\n",
    "sample_to_plot = random.randrange(0, len(test_loader))\n",
    "# sample_to_plot = 64\n",
    "# 2nd one is 25\n",
    "for i,sample in enumerate(test_loader):\n",
    "    if i==sample_to_plot:\n",
    "        image = sample[\"image\"]\n",
    "        target = sample[\"class_idx\"]\n",
    "        part_map = sample[\"part_map\"]\n",
    "        params = sample[\"params\"]\n",
    "        class_idxs = sample[\"class_idx\"]\n",
    "        image_idxs = sample[\"image_idx\"]\n",
    "        params = test_dataset.get_params_for_single(params)\n",
    "        image = image.cuda()\n",
    "        part_map = part_map.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "        score = {}\n",
    "        list_image.append(image)\n",
    "        output = model(image)\n",
    "        output_all.append(output)\n",
    "        target_all.append(target)\n",
    "        # original_score = output[0, target].item()\n",
    "\n",
    "        # get scores for removed parts\n",
    "        # bird_parts_keys = ['beak_model', 'eye_model', 'wing_model', 'tail_model', 'foot_model']\n",
    "        bird_parts_keys = list(test_dataset.parts.keys())\n",
    "\n",
    "        for remove_part in bird_parts_keys:\n",
    "            image2 = test_dataset.get_intervention(\n",
    "                class_idxs.squeeze(0).item(),\n",
    "                image_idxs.squeeze(0).item(),\n",
    "                [remove_part],\n",
    "            )[\"image\"]\n",
    "\n",
    "\n",
    "            image2 = image2.cuda(non_blocking=True)\n",
    "            list_image.append(image2)\n",
    "            output = model(image2)\n",
    "            output_all.append(output)\n",
    "\n",
    "            # score[remove_part.split(\"_\")[0]] = output[\n",
    "            #     0, target\n",
    "            # ].item()  # only keep part name, i.e. eye, instead of eye_model\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = torch.cat([output_all[x][\"importance\"] for x in range(len(output_all))]).detach().cpu().numpy()\n",
    "preds = torch.stack([torch.argmax(output_all[x][\"pred\"]) for x in range(len(output_all))]).detach().cpu().numpy()\n",
    "np_image = torch.cat(list_image).detach().cpu().numpy()\n",
    "np_similarity = torch.cat([output_all[x][\"similarity_prototype\"] for x in range(len(output_all))]).detach().cpu().numpy()\n",
    "labels = [target.item()]*len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_importance = importance[np.arange(importance.shape[0]), :, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_figures =  [3297 ,5168, 2078]\n",
    "idx_figures =  torch.arange(len(labels))\n",
    "# idx_figures = np.random.choice(len(labels), 3, replace=False)\n",
    "proto_per_figure = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_all = class_importance[idx_figures]\n",
    "top_proto_idx = np.argsort(importance_all, axis=1)[:, -proto_per_figure:]\n",
    "all_proto = np.unique(top_proto_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorblind_palette = return_colorblind_palette()\n",
    "dict_proto_color = {all_proto[i]: colorblind_palette[i] for i in range(len(all_proto))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"idx_figures\", idx_figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=proto_per_figure + 1, nrows=len(idx_figures), figsize=(16, 18)) #width, height\n",
    "bird_parts_all =[\"Initial\"] +  [f\"w/o {bird_parts}\" for bird_parts in bird_parts_keys]\n",
    "\n",
    "for idx_plot,idx_figure in enumerate(idx_figures):\n",
    "\n",
    "    image = np_image[idx_figure]\n",
    "    # image = unnormalize(torch.tensor(image)).numpy()\n",
    "    label_tmp = labels[idx_figure]\n",
    "    pred_tmp = preds[idx_figure]\n",
    "    importance_image = importance[idx_figure,:,label_tmp]\n",
    "    top_proto_idx_image = np.argsort(importance_image)[-proto_per_figure:]\n",
    "    top_proto_idx_image = top_proto_idx_image[::-1]\n",
    "    similarity = np_similarity[idx_figure]\n",
    "    top_proto_idx_image = top_proto_idx_image[importance_image[top_proto_idx_image]>0]\n",
    "    similarity = similarity[top_proto_idx_image]\n",
    "    img_size = image.shape[1:]\n",
    "    size_square_similarity = int(similarity.shape[1]**0.5)\n",
    "    color_annotations = [dict_proto_color[top_proto_idx_image[i]] for i in range(len(top_proto_idx_image))]\n",
    "    plot_prototypes(image, similarity,axs=axs[idx_plot,0], alpha=0.7, label=label_tmp,pred = pred_tmp,color_annotations=color_annotations)\n",
    "    axs[idx_plot,0].title.set_text(f\"{bird_parts_all[idx_plot]}: {importance_image.sum():.2f}\")\n",
    "    axs[idx_plot,0].title.set_fontsize(18)\n",
    "    for idx in range(len(similarity)):\n",
    "\n",
    "        idx_proto = top_proto_idx_image[idx]\n",
    "        similarity_proto = similarity[idx]\n",
    "        similiarity_tmp = similarity_proto.reshape(\n",
    "            size_square_similarity, size_square_similarity\n",
    "        )\n",
    "        similarity_scaled = torch.nn.functional.interpolate(\n",
    "            torch.tensor(similiarity_tmp[None, None, :, :]),\n",
    "            size=img_size,\n",
    "            scale_factor=None,\n",
    "            mode=\"bilinear\",\n",
    "        )\n",
    "\n",
    "        similarity_plot = show_cam_on_image(\n",
    "            np.transpose(image,(1,2,0)),\n",
    "            similarity_scaled[0, 0].detach().cpu().numpy(),\n",
    "        )\n",
    "        axs[idx_plot,idx + 1].imshow(similarity_plot,interpolation='nearest')\n",
    "        axs[idx_plot,idx + 1].title.set_text(f\"Importance: {importance_image[idx_proto]:.2f}\",\n",
    "        )\n",
    "        axs[idx_plot,idx + 1].title.set_fontsize(18)\n",
    "        # axs[idx_plot,idx + 1].title.set_fontsize(30)\n",
    "        # make tight layout\n",
    "        axs[idx_plot,idx + 1].axis(\"off\")\n",
    "        border = Rectangle(\n",
    "            (0, 0),\n",
    "            image.shape[1],\n",
    "            image.shape[0],\n",
    "            linewidth=4,\n",
    "            edgecolor=color_annotations[idx],\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "        # Add the border to the image\n",
    "        axs[idx_plot,idx + 1].add_patch(border)\n",
    "        plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
